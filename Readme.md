Developed and implemented CharCNN and CharLSTM architectures for text generation, drawing inspiration from the 'Unreasonable Effectiveness of RNNs' paper. I trained these models on Sherlock Holmes and Shakespearean text datasets. The models' performance was evaluated by their ability to generate increasingly coherent sentences starting from a blank input. This demonstrates my proficiency in designing and utilizing recurrent neural network (RNN) architectures for text generation tasks.